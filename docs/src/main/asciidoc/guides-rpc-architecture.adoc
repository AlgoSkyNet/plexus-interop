image::images/interop-messaging-architecture-layers.png[]

Interop Client consist of three layers:

* Application layer - strong-typed API used by end-client - application
* Protocol - generic implementation of RPC lifecycles for Client
* Transport - keeps connection and transfers messages between Client and Interop Broker.

Interop Broker consist of three layers:

* Core - validates invocations agains the metadata, implements discovery and other metadata-based capabilities
* Protocol - generic implementation of RPC lifecycles for Broker. It's similar to Client's protocol layer, but still has some differences.
* Transport - keeps connection and transfers messages between Client and Interop Broker.

==== Application Layer

Typically Application layer consist of strong-typed application-specific code which is auto-generated in the chosen language based on Interop Registry where application-level messages and services are described in .proto format.

For example, for service
[source]
----
service GreeterService {
  rpc Greet(GreetingRequest) returns (GreetingResponse);
}
----
in C# or Java language, class GreeterService containing method Greet will be generated. The method receives object of type GreetingRequest and returns object of type GreetingResponse which are also generated classes.

Implementation of such generated method does the following:

* Serializes the input message (= API method call parameter) into language-neutral format (e.g. binary array)
* Creates "request" object, which contains information about which API method was called plus some additional information about the caller
* Passes the request object and serialized input message into Protocol Level
* Waits for response from Protocol Level
* Once response has arrived:
** If response is successful - deserializes response message into strong-typed object and returns this object to the caller via handler that app code has registered
** If response is not successful - returns error to the caller

==== Protocol Layer

*Topic* is the main object of the Protocol Layer. 
Each topic holds the state of a single RPC invocation and changes it according to the received messages and other incoming events, e.g. timeout notifications, cancellations etc.
Topic is like a state machine instance describing RPC invocation lifecycle, so there are 4 types of topics for each of the supported lifecycles: Unary, Consumer Streaming, Provider Streaming, Bidirectional Streaming.

Protocol layer does the following:

* Creates and then tracks a topic for each new incoming or outcoming RPC invocation.
* Receives API calls from Client through Application Layer, converts them, and then routes to the corresponding topics.
* Receives messages from Broker through Transport Layer, deserializes them, and routes to the corresponding topics.
* Notifies Client about topic state changes by calling callbacks through Application Layer.
* Notifies Broker about topic state changes by sending messages through Protocol Layer.

Example of typical protocol-level message sent from Client to Broker, in pseudo-language:

----
Header:
    Type: "MethodInvocationRequest"
    Topic ID: "28069cd9-88ce-4460-976d-d3770487eaab"
    Message ID: "501e7961-9ec1-49e3-b3e3-4fdbd8358d10"
    Sender Type: "DB.GlobalMarkets.App"
    Sender Instance ID: "4efb7e26-3db8-4d68-8278-351499d1b43e"
    Receiver Type: "DB.GlobalMarkets.UserAdminApp"
    Receiver Instance ID: ""
    Service: "DB.GlobalMarkets.UserAdminService"
    Method: "GetUserInfo"
    Timeout: 30000
Body: 
    <binary blob - application-level message serialized via Protobuf>
----

==== Transport Layer

Transport layer does the following:

* Transfers serialized messages (e.g. binary blobs) from Client to Broker and vice versa.
* Tracks connection sessions via heartbeats or other mechanisms depending on a concrete transport implementation.
* Guarantees message delivery order
* Implements fault-tolerance for unreliable underlying protocols

The main objects of Transport Layer are Channels and Frames.

image::images/transport-framing-scheme.png[]

*Channel* is a logical group of input and output messages, usually corresponding to a protocol topic. Each channel consist of 2 message streams: input and output.
Channel can be opened by any side - Client or Broker. When channel is opened, other side receives notification about the new channel and starts to track it too.
When one side writes messages to output stream of a channel, the other side can read them from the input stream of the same channel.
Messages within each stream are transferred sequentially, one-by-one, and the transport implementation must guarantee their order. 
I.e. the order of messages written to output stream on one side must be equal to the order of messages received from input channel on the other side.

*Frame* is a part of message. Transport split messages to frames to achieve the following goals:

* Multiplexing: transfer messages in several channels concurrently through a limited amount of transport streams
* Fault-tolerance: retry sending only failed frame instead of re-sending full message when an error occurred

Example of typical transport-level message in pseudo-language:

----
Channel ID: "85fba277-bdbc-48ef-ae57-435e78a35c2b"
Message ID: 1
Frame ID: 3
PositionFlags: LastInMessage, LastInChannel
Length: 1023
Body: [binary blob]
----

By default, Desktop Plexus uses Named Pipe Transport to transfer messages between Client and Broker.
However, it is possible to plug in custom Transport into Desktop Plexus - e.g. TCP-based or WebSocket-based implementation.

===== Reference implementation: Named Pipe Transport

Named Pipe Transport sends messages between processes using, as you may have guessed, named pipes.

Pipe is a stream-based transport. This means that each connection consist of 2 binary streams: input and output. This leads to several implementation details:

* Stream is just an infinite sequence of bytes, so we manually delimit one message from another.
* There is only one stream for each direction, so we split messages to frames and send them in round-robin order. 
This allows concurrent message transferring, and also small messages does not need to wait while stream is busy 
by a big message transfer. In fact, we make all messages small.
* There is no notifications when other side stopped listening the pipe. The only way to detect this is to try sending message.
So we send heartbeats to pipe to check the other side is still online.

For the specification of Named Pipe Transport protocol, please check the section <<Named Pipe Transport protocol>>.